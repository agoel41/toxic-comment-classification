{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic classification using Bidirectional LSTM (Bidirectional RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "- Download the data: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "- Download the word vectors: http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors....\n",
      "Found 400000 word vectors.\n",
      "Embedding dimensions:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading word vectors....')\n",
    "word2vec = {}\n",
    "\n",
    "with open(os.path.join('Embeddings/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "     # The file contains just a space-separated text file in the format:\n",
    "     # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        # splits at spaces\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        #np.asarray Converts the input to an array.\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "print('Embedding dimensions: ', word2vec['the'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading comments\n",
      "Number of training examples in training set: 159571\n",
      "Training set shape: (159571, 8)\n",
      "Training set targets shape: (159571, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading comments')\n",
    "\n",
    "train = pd.read_csv('data/toxic_comment/train.csv', header = 0)\n",
    "sentences = train['comment_text'].fillna('DUMMY_VALUE').values\n",
    "possible_labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "#possible_labels = train.columns.values[2:]\n",
    "targets = train[possible_labels].values\n",
    "print('Number of training examples in training set:' , train.shape[0])\n",
    "print('Training set shape:', train.shape)\n",
    "print('Training set targets shape:', targets.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394.0732213246768 590.7202819048919 5000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAdg0lEQVR4nO3dfZQdVZnv8e/PQBBFSCANFxOuCZrRic6omAEURxE0BHAZHEHD6CVClhkRx7eZK4neJYqyBgYHlauDRhMJDhoi6hB5MUReBkchJrwnREwbEPqCpDG8RFE08bl/1HPk0DndXd1d5zTn9O+z1lmn6qldVXv36vSTqtq1tyICMzOzKj1rtCtgZmadx8nFzMwq5+RiZmaVc3IxM7PKObmYmVnldhntCjxTTJo0KaZOnTra1TAzays333zzwxHR1Tfu5JKmTp3KunXrRrsaZmZtRdIvG8V9W8zMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKuc39CswdeEVo3bue88+dtTObWbWH1+5mJlZ5ZxczMysck4uZmZWOScXMzOrnJOLmZlVrmnJRdJSSVskra+LnSvpZ5LukPQ9SRPqti2S1C3pbklH1cVnZ6xb0sK6+DRJayRtknSJpPEZ3y3Xu3P71Ga10czMGmvmlcuFwOw+sdXAyyLir4GfA4sAJM0A5gIvzX3+XdI4SeOALwFHAzOAE7MswDnA5yJiOvAIMD/j84FHIuJFwOeynJmZtVDTkktE3ABs7RO7OiK25+pNwJRcngMsj4gnI+IeoBs4OD/dEbE5Iv4ALAfmSBJwBHBp7r8MOK7uWMty+VLgyCxvZmYtMprPXE4BrsrlycD9ddt6MtZffB/g0bpEVYs/7Vi5/bEsb2ZmLTIqyUXSx4HtwMW1UINiMYz4QMdqVI8FktZJWtfb2ztwpc3MrLSWJxdJ84A3A++MiNof/R7ggLpiU4AHBog/DEyQtEuf+NOOldv3os/tuZqIWBwRMyNiZldX10ibZmZmqaXJRdJs4HTgLRHxRN2mlcDc7Ok1DZgO/BRYC0zPnmHjKR76r8ykdB1wfO4/D7is7ljzcvl44Nq6JGZmZi3QtIErJX0LOByYJKkHOIOid9huwOp8xn5TRLw3IjZIWgHcRXG77LSI2JHHeT+wChgHLI2IDXmK04Hlkj4D3AosyfgS4BuSuimuWOY2q41mZtZY05JLRJzYILykQaxW/izgrAbxK4ErG8Q3U/Qm6xv/PXDCkCprZmaV8hv6ZmZWOScXMzOrnJOLmZlVzsnFzMwq5+RiZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKufkYmZmlXNyMTOzyjm5mJlZ5ZxczMysck1LLpKWStoiaX1dbG9JqyVtyu+JGZek8yV1S7pD0kF1+8zL8pskzauLv0rSnbnP+ZI00DnMzKx1mnnlciEwu09sIXBNREwHrsl1gKOB6flZAFwARaIAzgAOAQ4GzqhLFhdk2dp+swc5h5mZtUjTkktE3ABs7ROeAyzL5WXAcXXxi6JwEzBB0v7AUcDqiNgaEY8Aq4HZuW3PiLgxIgK4qM+xGp3DzMxapNXPXPaLiAcB8nvfjE8G7q8r15OxgeI9DeIDnWMnkhZIWidpXW9v77AbZWZmTzdocpG0n6Qlkq7K9RmS5ldcDzWIxTDiQxIRiyNiZkTM7OrqGuruZmbWjzJXLhcCq4Dn5/rPgQ8N83wP5S0t8ntLxnuAA+rKTQEeGCQ+pUF8oHOYmVmLlEkukyJiBfAngIjYDuwY5vlWArUeX/OAy+riJ2WvsUOBx/KW1ipglqSJ+SB/FrAqt22TdGj2Ejupz7EancPMzFpklxJlfitpH/K2U+2P/2A7SfoWcDgwSVIPRa+vs4EVeVvtPuCELH4lcAzQDTwBnAwQEVslfRpYm+XOjIhaJ4FTKa6qdgeuyg8DnMPMzFqkTHL5CMXVwAsl/RjoAo4fbKeIOLGfTUc2KBvAaf0cZymwtEF8HfCyBvFfNzqHmZm1zqDJJSJukfR64MUUD9Lvjog/Nr1mZmbWtsr0FjsN2CMiNkTEemAPSe9rftXMzKxdlXmg/56IeLS2ki8zvqd5VTIzs3ZXJrk8qzZuF4CkccD45lXJzMzaXZkH+qsoel99maLH2HuBHzS1VmZm1tbKJJfTgX+g6Por4Grga82slJmZtbcyvcX+RDEC8QXNr46ZmXWCQZOLpMOATwIvyPKieDXlwOZWzczM2lWZ22JLgA8DNzP8YV/MzGwMKZNcHouIqwYvZmZmViiTXK6TdC7wXeDJWjAibmlarczMrK2VSS6H5PfMulgAR1RfHTMz6wRleou9oRUVMTOzzvFMmYnSzMw6SKtnojQzszGg1TNRmpnZGFAmuQxrJkozMxu7hjsTpacONjOzfpVJLhuAp81ESbkrHjMzG6PKJIkbI2J7bSbKnOL4xmZXzMzM2le/Vy6S/gcwGdhd0isprloA9gSe04K6mZlZmxrotthRwLuBKcB5dfFtwMeaWCczM2tz/SaXiFgGLJP0toj4TgvrZGZmba7MA/3LJf09MLW+fESc2axKmZlZeyvzQP8yYA6wHfht3WfYJH1Y0gZJ6yV9S9KzJU2TtEbSJkmXSBqfZXfL9e7cPrXuOIsyfreko+riszPWLWnhSOpqZmZDV+bKZUpEzK7qhJImAx8AZkTE7yStAOYCxwCfi4jlkr4MzKeYWnk+8EhEvEjSXOAc4B2SZuR+L6UYmuaHkv4iT/Ml4E1AD7BW0sqIuKuqNpiZ2cDKXLn8RNJfVXzeXSh6oe1C0fPsQYoh/C/N7cuA43J5Tq6T24+UpIwvj4gnI+IeoBs4OD/dEbE5Iv4ALM+yZmbWImWSy2uBm/M20x2S7pR0x3BPGBH/D/gscB9FUnmMYgrlR3PcMiiuOCbn8mTg/tx3e5bfpz7eZ5/+4juRtEDSOknrent7h9skMzPro8xtsaOrPKGkiRRXEtOAR4Fv93OOqO3Sz7b+4o0SZjSIERGLgcUAM2fObFjGzMyGbtArl4j4JXAAcEQuP1FmvwG8EbgnInrzbf/vAq8BJuRtMijerXkgl3vy/OT2vYCt9fE++/QXNzOzFikzWdgZwOnAogztCvzHCM55H3CopOfks5MjgbuA64Djs8w8il5qUAyaOS+XjweujYjI+NzsTTYNmA78FFgLTM/eZ+MpHvqvHEF9zcxsiMrcFnsr8ErgFoCIeEDS84Z7wohYI+nSPN524FaKW1NXAMslfSZjS3KXJcA3JHVTXLHMzeNsyJ5md+VxTouIHQCS3k8xwdk4YGlEbBhufc3MbOjKJJc/RERIqs3n8tyRnjQizgDO6BPeTNHTq2/Z39PPEP8RcRZwVoP4lcCVI62nmZkNT5lnJyskfYXimch7gB8CX21utczMrJ0NeuUSEZ+V9CbgcYo5XT4REaubXjMzM2tbgyaXvA12bUSslvRi4MWSds2eXmZmZjspc1vsBmC3HLblh8DJwIXNrJSZmbW3MslFEfEE8HfA/42ItwIzmlstMzNrZ6WSi6RXA++k6C4M5XqZmZnZGFUmuXyQ4gXK7+W7JQdSvPBoZmbWUJneYjdQPHeprW+mGDLfzMysoZGMEWZmZtaQk4uZmVXOycXMzCpX5iXKLuA9wNT68hFxSvOqZWZm7axMl+LLgB9RvEC5o7nVMTOzTlAmuTwnIk5vek3MzKxjlHnmcrmkY5peEzMz6xhlX6K8XNLvJD0uaZukx5tdMTMza19lXqIc9qyTZmY2NvWbXCS9JCJ+JumgRtsj4pbmVcvMzNrZQFcuHwEWAP/WYFsARzSlRmZm1vb6TS4RsSC/39C66piZWSfwG/pmZlY5JxczM6uck4uZmVVu0OQi6TBJz83ld0k6T9ILml81MzNrV2WuXC4AnpD0cuCjwC+Bi0ZyUkkTJF0q6WeSNkp6taS9Ja2WtCm/J2ZZSTpfUrekO+q7Rkual+U3SZpXF3+VpDtzn/MlaST1NTOzoSmTXLZHRABzgC9ExBeAkb5Y+QXgBxHxEuDlwEZgIXBNREwHrsl1gKOB6flZQJHskLQ3cAZwCHAwcEYtIWWZBXX7zR5hfc3MbAjKJJdtkhYB7wKukDQO2HW4J5S0J/A6YAlARPwhIh6lSF7Lstgy4LhcngNcFIWbgAmS9geOAlZHxNaIeARYDczObXtGxI2ZFC+qO5aZmbVAmeTyDuBJYH5E/AqYDJw7gnMeCPQCX5d0q6Sv5TOd/SLiQYD83jfLTwbur9u/J2MDxXsaxHciaYGkdZLW9fb2jqBJZmZWb9DkEhG/iojzIuJHuX5fRIzkmcsuwEHABRHxSuC3PHULrJFGz0tiGPGdgxGLI2JmRMzs6uoauNZmZlZav8mlNvpxf58RnLMH6ImINbl+KUWyeShvaZHfW+rKH1C3/xTggUHiUxrEzcysRfpNLhHxvIjYE/g8xZXFZIo/1KcDnxnuCfPW2v2SXpyhI4G7gJVArcfXPIoZMMn4Sdlr7FDgsbxttgqYJWliPsifBazKbdskHZq9xE6qO5aZmbVAmZkoj4qIQ+rWL5C0BvjXEZz3H4GLJY0HNgMnUyS6FZLmA/cBJ2TZK4FjgG7giSxLRGyV9GlgbZY7MyK25vKpwIXA7sBV+TEzsxYpk1x2SHonsJzi2cWJwI6RnDQibgNmNth0ZIOyAZzWz3GWAksbxNcBLxtJHc3MbPjK9Bb7e+DtwEP5OSFjZmZmDQ145ZLvtLw1Iua0qD5mZtYBBrxyiYgdFC8xmpmZlVbmmcuPJX0RuITinRTA0xybmVn/yiSX1+T3mXUxT3NsZmb9GjS5eJpjMzMbqjLzueyVc7isy8+/SdqrFZUzM7P2VKYr8lJgG0V35LcDjwNfb2alzMysvZV55vLCiHhb3fqnJN3WrAqZmVn7K3Pl8jtJr62tSDoM+F3zqmRmZu2uzJXLqcCyfM4iYCtPDTBpZma2kzK9xW4DXp4zSBIRIxlu38zMxoAyvcV+IeliivHEpgxW3szMrMwzlxnAV4B9gM9K2izpe82tlpmZtbMyyWUH8Mf8/hPFyMhbBtzDzMzGtDIP9B8H7gTOA74aEb9ubpXMzKzdlblyORG4AXgfsFzSpyTtNKmXmZlZTZneYpcBl0l6CXA08CHgoxRTCJuZme2kTG+x70j6BfAF4LnAScDEZlfMzMzaV5lnLmcDt+TEYWZmZoMqc1tsbSsqYmZmnaPMA30zM7Mh6Te55ACVSNqtddUxM7NOMNCVy/n5fWMrKmJmZp1joOTyR0lfByZLOr/vZ6QnljRO0q2SLs/1aZLWSNok6RJJ4zO+W6535/apdcdYlPG7JR1VF5+dsW5JC0daVzMzG5qBksubgVXA74GbG3xG6oPAxrr1c4DPRcR04BFgfsbnA49ExIuAz2U5JM0A5gIvBWYD/54JaxzwJYp3cmYAJ2ZZMzNrkX57i0XEwxRv5G+MiNurPKmkKcCxwFnARyQJOIJi5GWAZcAngQuAObkMcCnwxSw/B1geEU8C90jqBg7Oct0RsTnPtTzL3lVlG8zMrH9leov9WtL3JG2R9FC+VDnSofc/T/GW/59yfR/g0YjYnus9wORcngzcD5DbH8vyf4732ae/+E4kLZC0TtK63t7eETbJzMxqyiSXrwMrgedT/JH+fsaGRdKbgS0RUX9rTQ2KxiDbhhrfORixOCJmRsTMrq6uAWptZmZDUeYN/X0joj6ZXCjpQyM452HAWyQdAzwb2JPiSmaCpF3y6mQK8ECW7wEOAHok7QLsRTHVci1eU79Pf3EzM2uBMlcuvZLeVXtYLuldwLCH3Y+IRRExJSKmUjyQvzYi3glcBxyfxeYBl+Xyylwnt18bEZHxudmbbBowHfgpsBaYnr3Pxuc5Vg63vmZmNnRlksspwNuBXwEPUvyBP6UJdTmd4uF+N8UzlSUZXwLsk/GPAAsBImIDsILiQf0PgNMiYkde+byfoqfbRmBFljUzsxYpM7bYfcBbmnHyiLgeuD6XN/NUb6/6Mr8HTuhn/7Moepz1jV8JXFlhVc3MbAg8tpiZmVXOycXMzCrn5GJmZpUrMxPl/6lb9gjJZmY2qIGG3P+opFfzVPdg8AjJZmZWwkC9xe6m6KV1oKQfUXTr3UfSiyPi7pbUzszM2tJAt8UeAT4GdAOH89T8Lgsl/aTJ9TIzszY20JXLbOAM4IXAecDtwG8j4uRWVMzMzNpXv1cuEfGxiDgSuBf4D4pE1CXpvyV9v0X1MzOzNlRm4MpVEbEWWCvp1Ih4raRJza6YmZm1r0G7IkfER+tW352xh5tVITMza39Deomy6hkpzcysM/kNfTMzq5yTi5mZVc7JxczMKufkYmZmlXNyMTOzyjm5mJlZ5ZxczMysck4uZmZWOScXMzOrnJOLmZlVzsnFzMwq5+RiZmaVa3lykXSApOskbZS0QdIHM763pNWSNuX3xIxL0vmSuiXdIemgumPNy/KbJM2ri79K0p25z/mS1Op2mpmNZaNx5bId+KeI+EvgUOA0STOAhcA1ETEduCbXAY4GpudnAXABFMmIYqbMQ4CDgTNqCSnLLKjbb3YL2mVmZqnMZGGViogHgQdzeZukjcBkYA5weBZbBlwPnJ7xiyIigJskTZC0f5ZdHRFbASStBmZLuh7YMyJuzPhFwHHAVa1oX6tNXXjFqJz33rOPHZXzmll7GNVnLpKmAq8E1gD7ZeKpJaB9s9hk4P663XoyNlC8p0G80fkXSFonaV1vb+9Im2NmZmnUkoukPYDvAB+KiMcHKtogFsOI7xyMWBwRMyNiZldX12BVNjOzkkYluUjalSKxXBwR383wQ3m7i/zekvEe4IC63acADwwSn9IgbmZmLTIavcUELAE2RsR5dZtWArUeX/OAy+riJ2WvsUOBx/K22SpglqSJ+SB/FrAqt22TdGie66S6Y5mZWQu0/IE+cBjwv4A7Jd2WsY8BZwMrJM0H7gNOyG1XAscA3cATwMkAEbFV0qeBtVnuzNrDfeBU4EJgd4oH+R35MN/M7JlqNHqL/TeNn4sAHNmgfACn9XOspcDSBvF1wMtGUE0zMxsBv6FvZmaVc3IxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6uck4uZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxczMKjcaM1FaB5i68IpROe+9Zx87Kuc1s6HxlYuZmVXOycXMzCrn5GJmZpVzcjEzs8o5uZiZWeWcXMzMrHLuimxtZbS6QIO7QZsNRcdeuUiaLeluSd2SFo52fczMxpKOvHKRNA74EvAmoAdYK2llRNw1ujWzduYXR83K68jkAhwMdEfEZgBJy4E5gJOLtZ3RvBVoY0Mz/gPTqcllMnB/3XoPcEjfQpIWAAty9TeS7h7m+SYBDw9z33blNo8NbvMYoHNG1OYXNAp2anJRg1jsFIhYDCwe8cmkdRExc6THaSdu89jgNo8NzWhzpz7Q7wEOqFufAjwwSnUxMxtzOjW5rAWmS5omaTwwF1g5ynUyMxszOvK2WERsl/R+YBUwDlgaERuaeMoR31prQ27z2OA2jw2Vt1kROz2KMDMzG5FOvS1mZmajyMnFzMwq5+QyAp00xIykpZK2SFpfF9tb0mpJm/J7YsYl6fxs9x2SDqrbZ16W3yRp3mi0pSxJB0i6TtJGSRskfTDjHdtuSc+W9FNJt2ebP5XxaZLWZP0vyY4wSNot17tz+9S6Yy3K+N2SjhqdFpUnaZykWyVdnusd3WZJ90q6U9JtktZlrHW/2xHhzzA+FB0FfgEcCIwHbgdmjHa9RtCe1wEHAevrYv8KLMzlhcA5uXwMcBXF+0SHAmsyvjewOb8n5vLE0W7bAG3eHzgol58H/ByY0cntzrrvkcu7AmuyLSuAuRn/MnBqLr8P+HIuzwUuyeUZ+Tu/GzAt/y2MG+32DdL2jwDfBC7P9Y5uM3AvMKlPrGW/275yGb4/DzETEX8AakPMtKWIuAHY2ic8B1iWy8uA4+riF0XhJmCCpP2Bo4DVEbE1Ih4BVgOzm1/74YmIByPillzeBmykGN2hY9uddf9Nru6anwCOAC7NeN82134WlwJHSlLGl0fEkxFxD9BN8W/iGUnSFOBY4Gu5Ljq8zf1o2e+2k8vwNRpiZvIo1aVZ9ouIB6H4Qwzsm/H+2t62P5O89fFKiv/Jd3S78/bQbcAWij8WvwAejYjtWaS+/n9uW25/DNiHNmsz8Hngo8Cfcn0fOr/NAVwt6WYVQ11BC3+3O/I9lxYpNcRMh+qv7W35M5G0B/Ad4EMR8Xjxn9TGRRvE2q7dEbEDeIWkCcD3gL9sVCy/277Nkt4MbImImyUdXgs3KNoxbU6HRcQDkvYFVkv62QBlK2+zr1yGbywMMfNQXhqT31sy3l/b2+5nImlXisRycUR8N8Md326AiHgUuJ7iHvsESbX/bNbX/89ty+17Udw+bac2Hwa8RdK9FLevj6C4kunkNhMRD+T3For/RBxMC3+3nVyGbywMMbMSqPUOmQdcVhc/KXuYHAo8lpfYq4BZkiZmL5RZGXtGyvvoS4CNEXFe3aaObbekrrxiQdLuwBspnjVdBxyfxfq2ufazOB64NoonvSuBudmzahowHfhpa1oxNBGxKCKmRMRUin+n10bEO+ngNkt6rqTn1ZYpfifX08rf7dHu0dDOH4oeFj+nuGf98dGuzwjb8i3gQeCPFP9bmU9xn/kaYFN+751lRTEZ2y+AO4GZdcc5heJBZzdw8mi3a5A2v5biEv8O4Lb8HNPJ7Qb+Grg127we+ETGD6T4Q9kNfBvYLePPzvXu3H5g3bE+nj+Lu4GjR7ttJdt/OE/1FuvYNmfbbs/Phtrfp1b+bnv4FzMzq5xvi5mZWeWcXMzMrHJOLmZmVjknFzMzq5yTi5mZVc7JxcYUSb8ZvNSQj/kKScfUrX9S0j+P4HgnqBip+bpqarjT8Q+X9JpmHNusxsnFbOReQfF+TFXmA++LiDdUeMx6hwNOLtZUTi42Zkn635LW5vwVtXlNpuZVw1dVzHdydb7JjqS/ybI3SjpX0vocneFM4B05b8Y78vAzJF0vabOkD/Rz/hNzvo31ks7J2CcoXu78sqRz+5TfX9INeZ71kv4247OyTrdI+naOlVabz+NTGb9T0ktygM73Ah/O4/xtvrX/nfxZrJV0WO7/SRXz/OzUDkkn5c/idknfyFjD49gYNdpvkvrjTys/wG/yexawmOLN5GcBl1PMaTMV2A68IsutAN6Vy+uB1+Ty2eTcN8C7gS/WneOTwE8o5v2YBPwa2LVPPZ4P3Ad0UQwgey1wXG67nro3pOv2+SeeetN6HMUcNJOAG4DnZvx0nnrr/l7gH3P5fcDX6ur3z3XH/Sbw2lz+nxTD4fTbDuClFG+oT8pyew90HH/G5sejIttYNSs/t+b6HhRjRd0H3BMRt2X8ZmBqjsf1vIj4Sca/Cbx5gONfERFPAk9K2gLsRzGsTs3fANdHRC+ApIspktt/DnDMtcDSHGzzPyPiNkmvp5jE6sfFUGmMB26s26c2GOfNwN/1c9w3Ulxp1db3rI1L1U87jgAujYiHASJi60DHiWKuHBtjnFxsrBLwLxHxlacFi9tGT9aFdgC703jo8YH0PUbff2tDPR4RcYOk11FMevWNvG32CMVkTicOUo9Gdah5FvDqiPjd0ypYJIlG7RCNh11veBwbm/zMxcaqVcApdc8nJquY96KhKGbh25YjxkIxum7NNopbVEOxBni9pEmSxgEnAv810A6SXkAxL8lXKUZzPgi4CThM0ouyzHMk/cUg5+5b36uB99ed5xWD7H8N8HZJ+2T5vYd5HOtgTi42JkXE1RS3tm6UdCfFdLaDJYj5wGJJN1L87/2xjF9HcTuo/oH+YOd/EFiU+94O3BIRlw28F4cDt0m6FXgb8IW8rfZu4FuS7qBINi8Z5DjfB95ae6APfACYmQ/o76J44D9Q3TcAZwH/Jel2oDZdwZCOY53NoyKblSRpj8j55yUtBPaPiA+OcrXMnpH8zMWsvGMlLaL4d/NLiisGM2vAVy5mZlY5P3MxM7PKObmYmVnlnFzMzKxyTi5mZlY5JxczM6vc/wdbaOAiK6kysQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The length of the comments varies a lot.\n",
    "lengths = train.comment_text.str.len()\n",
    "print(lengths.mean(), lengths.std(), lengths.max())\n",
    "plt.hist(lengths)\n",
    "plt.xlabel('length of sentence')\n",
    "plt.ylabel('# of words in sentence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the sentences (string) into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "#print('sequences:', sequences); exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: [\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\"] \n",
      "\n",
      "Sentence in a sequence form: [[688, 75, 1, 126, 130, 177, 29, 672, 4511, 12052, 1116, 86, 331, 51, 2278, 11448, 50, 6864, 15, 60, 2756, 148, 7, 2937, 34, 117, 1221, 15190, 2825, 4, 45, 59, 244, 1, 365, 31, 1, 38, 27, 143, 73, 3462, 89, 3085, 4583, 2273, 985]] \n",
      "\n",
      "Max sequence length: 1400\n",
      "Min sequence length: 0\n",
      "median sequence length: 35\n"
     ]
    }
   ],
   "source": [
    "print('Sentence: %s \\n' % sentences[0:1])\n",
    "print('Sentence in a sequence form: %s \\n' % sequences[0:1])\n",
    "\n",
    "print('Max sequence length:', max(len(s) for s in sequences))\n",
    "print('Min sequence length:', min(len(s) for s in sequences))\n",
    "s = sorted(len(s) for s in sequences)\n",
    "print('median sequence length:', s[len(s)//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to integer mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210337 unique tokens.\n",
      "Explanation --> 688\n",
      "Why --> 75\n",
      "the --> 1\n",
      "edits --> 126\n",
      "made --> 130\n",
      "under --> 177\n",
      "my --> 29\n",
      "username --> 672\n",
      "Hardcore --> 4511\n",
      "Metallica --> 12052\n",
      "Fan --> 1116\n",
      "were --> 86\n",
      "reverted? --> NA\n",
      "They --> 51\n",
      "weren't --> 2278\n",
      "vandalisms, --> NA\n",
      "just --> 50\n",
      "closure --> 6864\n",
      "on --> 15\n",
      "some --> 60\n",
      "GAs --> 2756\n",
      "after --> 148\n",
      "I --> 7\n",
      "voted --> 2937\n",
      "at --> 34\n",
      "New --> 117\n",
      "York --> 1221\n",
      "Dolls --> 15190\n",
      "FAC. --> NA\n",
      "And --> 4\n",
      "please --> 45\n",
      "don't --> 59\n",
      "remove --> 244\n",
      "the --> 1\n",
      "template --> 365\n",
      "from --> 31\n",
      "the --> 1\n",
      "talk --> 38\n",
      "page --> 27\n",
      "since --> 143\n",
      "I'm --> 73\n",
      "retired --> 3462\n",
      "now.89.205.38.27 --> NA\n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word2idx)))\n",
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "for w in ''.join(sentences[0:1]).split():         \n",
    "    if w.lower() in word2idx:\n",
    "       print('{} --> {}'.format(w, word2idx[w.lower()]))\n",
    "    else:\n",
    "        print('{} --> {}'.format(w, 'NA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (159571, 100)\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix where N is number of samples (examples) and T is sequence length\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data:', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Pre-trained embeddings\n",
      "Shape of Embeddings matrix:  (20000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Filling Pre-trained embeddings')\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2vec)+1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in the embedding index will all be zero\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 20000 words each of 100 dimensions\n",
    "print('Shape of Embeddings matrix: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0915 12:10:46.216710 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words, \n",
    "                            EMBEDDING_DIM, \n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Bi-directional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0915 12:10:46.247855 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0915 12:10:46.252668 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0915 12:10:46.262837 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0915 12:10:46.263841 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0915 12:10:46.719983 140158861489984 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0915 12:10:46.727146 140158861489984 deprecation.py:323] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 30)           13920     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 186       \n",
      "=================================================================\n",
      "Total params: 2,014,106\n",
      "Trainable params: 14,106\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Building model:')\n",
    "\n",
    "# Create an LSTM network with a single LSTM.\n",
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(input_)\n",
    "x = Bidirectional(LSTM(15, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "\n",
    "output = Dense(len(possible_labels), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(input_, output)\n",
    "model.compile(loss='binary_crossentropy', optimizer = Adam(lr=0.01), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/10\n",
      "127656/127656 [==============================] - 384s 3ms/step - loss: 0.0700 - acc: 0.9768 - val_loss: 0.0553 - val_acc: 0.9806\n",
      "Epoch 2/10\n",
      "127656/127656 [==============================] - 376s 3ms/step - loss: 0.0522 - acc: 0.9812 - val_loss: 0.0516 - val_acc: 0.9813\n",
      "Epoch 3/10\n",
      "127656/127656 [==============================] - 382s 3ms/step - loss: 0.0497 - acc: 0.9820 - val_loss: 0.0520 - val_acc: 0.9814\n",
      "Epoch 4/10\n",
      "103680/127656 [=======================>......] - ETA: 1:13 - loss: 0.0484 - acc: 0.9823"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, targets, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('static/acc_toxic_bilstm.png')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('static/loss_toxic_bilstm.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(data)\n",
    "aucs = []\n",
    "for j in range(6):\n",
    "    auc = roc_auc_score(targets[:, j], p[:, j])\n",
    "    aucs.append(auc)\n",
    "print(np.mean(aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
